{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test)= tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "x_train,x_test = x_train.reshape([-1,784]),x_test.reshape([-1,784])\n",
    "x_train,x_test = x_train/255,x_test/255.\n",
    "y_train, y_test = tf.one_hot(y_train, depth=10),tf.one_hot(y_test, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "num_epochs =30\n",
    "batch_size= 256\n",
    "display_stpe =1\n",
    "input_size =784\n",
    "hidden1_size =256\n",
    "hidden2_size =256\n",
    "output_size =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data =  train_data.shuffle(60000).batch(batch_size)\n",
    "\n",
    "def random_normal_intializer_with_stddev_1():\n",
    "    return tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "       super(ANN, self).__init__()\n",
    "       self.hidden_layer_1 = tf.keras.layers.Dense(hidden1_size,\n",
    "                                                activation='relu',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "       self.hidden_layer_2 = tf.keras.layers.Dense(hidden2_size,\n",
    "                                                activation='relu',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "       self.output_layer = tf.keras.layers.Dense(output_size,\n",
    "                                              activation=None,\n",
    "                                              kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                              bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "       \n",
    "       def call(self, x):\n",
    "         H1_output = self.hidden_layer_1(x)\n",
    "         H2_output = self.hidden_layer_2(H1_output)\n",
    "         logits = self.output_layer(H2_output)\n",
    "\n",
    "         return logits\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cross-entropy 손실 함수를 정의합니다.\n",
    "@tf.function\n",
    "def cross_entropy_loss(logits, y):\n",
    "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "# 최적화를 위한 Adam 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model,x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_prd = model(x)\n",
    "        loss = cross_entropy_loss(y_prd,y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_accuracy(y_prd, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_prd,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model = ANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/var/folders/by/m4xy631x2snc43fg1lswdxd00000gn/T/ipykernel_59571/3542757828.py\", line 4, in train_step  *\n        y_prd = model(x)\n    File \"/Users/nicolekan/anaconda3/envs/AI/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nicolekan/anaconda3/envs/AI/lib/python3.8/site-packages/keras/engine/training.py\", line 584, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer \"ann_2\" \"                 f\"(type ANN).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer \"ann_2\" \"                 f\"(type ANN):\n      • inputs=tf.Tensor(shape=(256, 784), dtype=float32)\n      • training=None\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# 모든 배치들에 대해서 최적화를 수행합니다.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m batch_x, batch_y \u001b[39min\u001b[39;00m train_data:\n\u001b[1;32m      6\u001b[0m   \u001b[39m# 옵티마이저를 실행해서 파라마터들을 업데이트합니다.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m   _, current_loss \u001b[39m=\u001b[39m train_step(ANN_model, batch_x, batch_y), cross_entropy_loss(ANN_model(batch_x), batch_y)\n\u001b[1;32m      8\u001b[0m   \u001b[39m# 평균 손실을 측정합니다.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m   average_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m current_loss \u001b[39m/\u001b[39m total_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/by/m4xy631x2snc43fg1lswdxd00000gn/T/__autograph_generated_filekceyis74.py:9\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mFunctionScope(\u001b[39m'\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mConversionOptions(recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, user_requested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, optional_features\u001b[39m=\u001b[39m(), internal_convert_user_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)) \u001b[39mas\u001b[39;00m fscope:\n\u001b[1;32m      8\u001b[0m     \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m----> 9\u001b[0m         y_prd \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(model), (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     10\u001b[0m         loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(cross_entropy_loss), (ag__\u001b[39m.\u001b[39mld(y_prd), ag__\u001b[39m.\u001b[39mld(y)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m     gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(model)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/keras/engine/training.py:584\u001b[0m, in \u001b[0;36mModel.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdoc_in_current_and_subclasses\n\u001b[1;32m    560\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    561\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs and returns the outputs as tensors.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \n\u001b[1;32m    563\u001b[0m \u001b[39m    In this case `call()` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    585\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnimplemented `tf.keras.Model.call()`: if you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mintend to create a `Model` with the Functional \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    587\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAPI, please provide `inputs` and `outputs` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marguments. Otherwise, subclass `Model` with an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moverridden `call()` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/var/folders/by/m4xy631x2snc43fg1lswdxd00000gn/T/ipykernel_59571/3542757828.py\", line 4, in train_step  *\n        y_prd = model(x)\n    File \"/Users/nicolekan/anaconda3/envs/AI/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nicolekan/anaconda3/envs/AI/lib/python3.8/site-packages/keras/engine/training.py\", line 584, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer \"ann_2\" \"                 f\"(type ANN).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer \"ann_2\" \"                 f\"(type ANN):\n      • inputs=tf.Tensor(shape=(256, 784), dtype=float32)\n      • training=None\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  average_loss = 0.\n",
    "  total_batch = int(x_train.shape[0] / batch_size)\n",
    "  # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "  for batch_x, batch_y in train_data:\n",
    "    # 옵티마이저를 실행해서 파라마터들을 업데이트합니다.\n",
    "    _, current_loss = train_step(ANN_model, batch_x, batch_y), cross_entropy_loss(ANN_model(batch_x), batch_y)\n",
    "    # 평균 손실을 측정합니다.\n",
    "    average_loss += current_loss / total_batch\n",
    "  # 지정된 epoch마다 학습결과를 출력합니다.\n",
    "  if epoch % display_step == 0:\n",
    "    print(\"반복(Epoch): %d, 손실 함수(Loss): %f\" % ((epoch+1), average_loss))\n",
    "\n",
    "# 테스트 데이터를 이용해서 학습된 모델이 얼마나 정확한지 정확도를 출력합니다.\n",
    "print(\"정확도(Accuracy): %f\" % compute_accuracy(ANN_model(x_test), y_test)) # 정확도: 약 94%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
